# -*- coding: utf-8 -*-
"""animal_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fVtLuOtFMKRVTNQvskKZpLqQH7srdq1B

**Mount google drive with collab**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Convert mp3 files to wav files using Audiosegment class of pydub**"""

!pip install pydub ffmpeg --quiet
from pydub import AudioSegment
import os
def convert_mp3_to_wav(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(".mp3"):
            mp3_path = os.path.join(folder_path, filename)
            wav_path = os.path.splitext(mp3_path)[0] + ".wav"

            try:
                sound = AudioSegment.from_mp3(mp3_path)
                sound.export(wav_path, format="wav")
                print(f"‚úÖ Converted: {filename} ‚Üí {os.path.basename(wav_path)}")
            except Exception as e:
                print(f"‚ùå Failed to convert {filename}: {e}")

"""Calling the function"""

monkey_mp3_folder = '/content/drive/MyDrive/animal_sounds/monkeys'
convert_mp3_to_wav(monkey_mp3_folder)

"""Deleting mp3 files from folder"""

import os

def delete_mp3_files(folder_path):
    deleted = 0
    for file in os.listdir(folder_path):
        if file.endswith('.mp3'):
            os.remove(os.path.join(folder_path, file))
            deleted += 1
    print(f"‚úÖ Deleted {deleted} MP3 file(s) from {folder_path}")

# Example usage:
delete_mp3_files('/content/drive/MyDrive/animal_sounds/monkeys')

import librosa
import numpy as np

def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_mfcc_energy = -np.inf
        best_mfcc = None

        # Slide over audio
        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)

            segment = audio[start_sample:end_sample]
            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            mfcc_mean = np.mean(mfcc.T, axis=0)
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_mfcc_energy:
                max_mfcc_energy = energy
                best_mfcc = mfcc_mean

        return best_mfcc
    except Exception as e:
        print(f"Error in {file_path}: {e}")
        return None

squi_mp3_folder = '/content/drive/MyDrive/animal_sounds/squirrels'
convert_mp3_to_wav(squi_mp3_folder)

"""**flush and mount**"""

from google.colab import drive
drive.flush_and_unmount()  # Unmount first
drive.mount('/content/drive')  # Then mount again

import matplotlib.pyplot as plt
import numpy as np

unique, counts = np.unique(labels, return_counts=True)


plt.figure(figsize=(6, 4))
plt.bar(unique, counts, color='skyblue')
plt.title("üìä Number of Samples per Class")
plt.xlabel("Class")
plt.ylabel("Count")
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

import os

def delete_mp3_files(folder_path):
    deleted = 0
    for file in os.listdir(folder_path):
        if file.endswith('.mp3'):
            os.remove(os.path.join(folder_path, file))
            deleted += 1
    print(f"‚úÖ Deleted {deleted} MP3 file(s) from {folder_path}")

# Example usage:
delete_mp3_files('/content/drive/MyDrive/animal_sounds/squirrels')

nowil_mp3_folder = '/content/drive/MyDrive/animal_sounds/no_wilds'
convert_mp3_to_wav(nowil_mp3_folder)

import os

def delete_mp3_files(folder_path):
    deleted = 0
    for file in os.listdir(folder_path):
        if file.endswith('.mp3'):
            os.remove(os.path.join(folder_path, file))
            deleted += 1
    print(f"‚úÖ Deleted {deleted} MP3 file(s) from {folder_path}")

# Example usage:
delete_mp3_files('/content/drive/MyDrive/animal_sounds/no_wilds')

"""**Feature extraction**"""

import os
import numpy as np
import librosa

# Extract best segment MFCCs from a file
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_mfcc_energy = -np.inf
        best_mfcc = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)

            segment = audio[start_sample:end_sample]
            if len(segment) < int(segment_duration * sr):
                continue  # skip short segments


            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            mfcc_mean = np.mean(mfcc.T, axis=0)
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_mfcc_energy:
                max_mfcc_energy = energy
                best_mfcc = mfcc_mean

        return best_mfcc
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Load data and extract features for all folders
def load_features_from_folders(base_path='/content/drive/MyDrive/animal_sounds'):
    features = []
    labels = []

    # Add your folders here
    class_folders = ['monkeys', 'squirrels', 'no_wilds']

    for label in class_folders:
        folder_path = os.path.join(base_path, label)
        if not os.path.exists(folder_path):
            print(f"Folder not found: {folder_path}")
            continue

        for file in os.listdir(folder_path):
            if file.endswith('.wav'):
                file_path = os.path.join(folder_path, file)
                feature = extract_best_features(file_path)
                if feature is not None:
                    features.append(feature)
                    labels.append(label)

    return np.array(features), np.array(labels)



"""**13 mfcc features extracted from 123 data samples**"""

X, y = load_features_from_folders('/content/drive/MyDrive/animal_sounds')
print("Features shape:", X.shape)
print("Labels shape:", y.shape)

"""**Feature extraction with more mfcc features**"""

import os
import numpy as np
import librosa

# üîç Function to extract the best (most energetic) feature segment from an audio file
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_energy = -np.inf
        best_features = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)

            segment = audio[start_sample:end_sample]
            if len(segment) < int(segment_duration * sr):
                continue  # Skip short segments

            # Feature extraction
            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            chroma = librosa.feature.chroma_stft(y=segment, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr)

            # Combine into a single feature vector
            feature_vector = np.hstack([
                np.mean(mfcc.T, axis=0),
                np.mean(chroma.T, axis=0),
                np.mean(contrast.T, axis=0)
            ])

            # Energy-based selection of best segment
            energy = np.sum(feature_vector ** 2)
            if energy > max_energy:
                max_energy = energy
                best_features = feature_vector

        return best_features
    except Exception as e:
        print(f"‚ùå Error processing {file_path}: {e}")
        return None


# üì¶ Function to load all audio files from subfolders and extract features
def load_features_from_folders(base_path='/content/drive/MyDrive/animal_sounds'):
    features = []
    labels = []

    class_folders = ['monkeys', 'squirrels', 'no_wilds']  # üëà Add your classes here

    for label in class_folders:
        folder_path = os.path.join(base_path, label)
        if not os.path.exists(folder_path):
            print(f"‚ö†Ô∏è Folder not found: {folder_path}")
            continue

        print(f"üîç Processing: {label}")
        for file in os.listdir(folder_path):
            if file.endswith('.wav'):
                file_path = os.path.join(folder_path, file)
                feature = extract_best_features(file_path)
                if feature is not None:
                    features.append(feature)
                    labels.append(label)

    return np.array(features), np.array(labels)

X, y = load_features_from_folders()
print(f"‚úÖ Loaded {len(X)} feature vectors with shape {X[0].shape} each.")

"""**SVM with 32 mfcc,52% accuracy**"""

import os
import numpy as np
import librosa
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# -------------------------------
# üì• Feature Extraction Function
# -------------------------------
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_energy = -np.inf
        best_features = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)
            segment = audio[start_sample:end_sample]

            if len(segment) < int(segment_duration * sr):
                continue

            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            chroma = librosa.feature.chroma_stft(y=segment, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr)

            # Mean features
            mfcc_mean = np.mean(mfcc.T, axis=0)
            chroma_mean = np.mean(chroma.T, axis=0)
            contrast_mean = np.mean(contrast.T, axis=0)

            combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_energy:
                max_energy = energy
                best_features = combined

        return best_features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# ---------------------------------
# üìÅ Load all audio into X and y
# ---------------------------------
def load_features_from_folders(base_path='/content/drive/MyDrive/animal_sounds'):
    features = []
    labels = []
    class_folders = ['monkeys', 'squirrels', 'no_wilds']

    for label in class_folders:
        folder_path = os.path.join(base_path, label)
        if not os.path.exists(folder_path):
            print(f"‚ùå Folder not found: {folder_path}")
            continue

        for file in os.listdir(folder_path):
            if file.endswith('.wav'):
                file_path = os.path.join(folder_path, file)
                feat = extract_best_features(file_path)
                if feat is not None:
                    features.append(feat)
                    labels.append(label)

    return np.array(features), np.array(labels)

# ----------------------------
# üöÄ Load data and preprocess
# ----------------------------
X, y = load_features_from_folders()

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# -------------------------
# üéØ Train SVM Model
# -------------------------
model = SVC(kernel='linear', probability=True)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)

print("\nüìä Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

print("\nüßæ Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

accuracy = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy: {accuracy * 100:.2f}%")

"""**Using SVC** **40% accuracy , 13 mfcc**"""

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Assuming you've already extracted features and labels:
# X = features (shape: [n_samples, 13])
# y = labels (shape: [n_samples])

# Encode string labels (monkey, squirrel, no_wilds) to numbers
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# Initialize and train the SVM model
model = SVC(kernel='linear', probability=True)
model.fit(X_train, y_train)

# Predict on test set
y_pred = model.predict(X_test)

# Evaluation
print("üìä Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

print("üßæ Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
from sklearn.metrics import accuracy_score

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"üéØ Accuracy: {accuracy * 100:.2f}%")

"""**predicts no wilds ..............,confusion between squirrels,monkeys(13 mfcc)**

"""

import librosa
import numpy as np
from sklearn.preprocessing import LabelEncoder
from google.colab import files

# Function to extract features from the audio file (same as used during training)
def extract_features(file_path, max_len=5):
    audio, sr = librosa.load(file_path, duration=max_len)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    mfcc = np.mean(mfcc.T, axis=0)
    return mfcc

# Function to predict whether the audio file is a monkey sound
def predict_animal_sound(file_path, model, label_encoder):
    feature = extract_features(file_path)

    if feature is not None:
        # Reshape feature for model (adding the extra dimension)
        feature = feature.reshape(1, -1)

        # Make prediction
        prediction = model.predict(feature)

        # Decode the prediction back to the label
        predicted_label = label_encoder.inverse_transform(prediction)
        return predicted_label[0]  # Returns the predicted label (e.g., 'monkey')
    else:
        return "Error extracting features."

# Upload a file
uploaded = files.upload()

# Path to the uploaded file (this will get the filename)
file_path = next(iter(uploaded))

# Predict the animal sound
predicted_label = predict_animal_sound(file_path, model, label_encoder)
print(f"Predicted label: {predicted_label}")

"""**preducting svm (32 mfcc)**"""

import librosa
import numpy as np
from sklearn.preprocessing import LabelEncoder
from google.colab import files

# üéØ Match feature extraction with training (32 features from best segment)
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_energy = -np.inf
        best_features = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)

            segment = audio[start_sample:end_sample]
            if len(segment) < int(segment_duration * sr):
                continue

            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            chroma = librosa.feature.chroma_stft(y=segment, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr)

            mfcc_mean = np.mean(mfcc.T, axis=0)
            chroma_mean = np.mean(chroma.T, axis=0)
            contrast_mean = np.mean(contrast.T, axis=0)

            combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_energy:
                max_energy = energy
                best_features = combined

        return best_features

    except Exception as e:
        print(f"‚ùå Error processing file: {e}")
        return None

# üß† Predict using trained model
def predict_animal_sound(file_path, model, label_encoder, scaler):
    feature = extract_best_features(file_path)
    if feature is not None:
        feature = feature.reshape(1, -1)
        feature_scaled = scaler.transform(feature)  # üí° Apply same scaling as training
        prediction = model.predict(feature_scaled)
        predicted_label = label_encoder.inverse_transform(prediction)
        return predicted_label[0]
    else:
        return "Error extracting features."

# üì§ Upload file and make prediction
uploaded = files.upload()
file_path = next(iter(uploaded))  # Get the filename
predicted_label = predict_animal_sound(file_path, model, label_encoder, scaler)
print(f"\nüîä Predicted label: {predicted_label}")

import librosa
import numpy as np
from sklearn.preprocessing import LabelEncoder
from google.colab import files

# Function to extract features from the audio file (same as used during training)
def extract_features(file_path, max_len=5):
    audio, sr = librosa.load(file_path, duration=max_len)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    mfcc = np.mean(mfcc.T, axis=0)
    return mfcc

# Function to predict whether the audio file is a monkey or squirrel sound
def predict_animal_sound(file_path, model, label_encoder):
    feature = extract_features(file_path)

    if feature is not None:
        # Reshape feature for model (adding the extra dimension)
        feature = feature.reshape(1, -1)

        # Predict the class
        prediction = model.predict(feature)

        # Get the class probabilities (confidence scores)
        probabilities = model.predict_proba(feature)

        # Get the predicted label (e.g., 'monkey', 'squirrel')
        predicted_label = label_encoder.inverse_transform(prediction)

        # Get the confidence of the prediction for the predicted class
        confidence = probabilities[0][prediction] * 100  # Convert to percentage

        # Prepare the message based on the confidence value
        if confidence > 50:  # If confidence is greater than 50%, we take it as a detection
            result_message = f"Wild animal presence detected!\nDetected as: {predicted_label[0]}\nConfidence: {confidence[0]:.2f}%\nAction required!"
        else:
            result_message = f"Uncertain detection.\nPredicted as: {predicted_label[0]}\nConfidence: {confidence[0]:.2f}%\nNo action required."

        return result_message
    else:
        return "Error extracting features."

# Upload a file
uploaded = files.upload()

# Path to the uploaded file (this will get the filename)
file_path = next(iter(uploaded))

# Predict the animal sound
result_message = predict_animal_sound(file_path, model, label_encoder)
print(result_message)

"""**Random forets training,13 mfcc,33.33% accuracy**"""

import os
import librosa
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix

# Path to your folder with 'monkeys', 'squirrels', 'no_wilds'
base_path = '/content/drive/MyDrive/animal_sounds'

# Extract features function
def extract_features(file_path):
    try:
        audio, sr = librosa.load(file_path, duration=5)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        mfcc_scaled = np.mean(mfcc.T, axis=0)
        return mfcc_scaled
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Data collection
features = []
labels = []
for label in os.listdir(base_path):
    class_dir = os.path.join(base_path, label)
    if os.path.isdir(class_dir):
        for file in os.listdir(class_dir):
            if file.endswith(".wav"):
                file_path = os.path.join(class_dir, file)
                feat = extract_features(file_path)
                if feat is not None:
                    features.append(feat)
                    labels.append(label)

# Encode labels
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(features, labels_encoded, test_size=0.2, stratify=labels_encoded, random_state=42)

# Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict
y_pred = rf_model.predict(X_test)

# Decode for reporting
y_test_labels = label_encoder.inverse_transform(y_test)
y_pred_labels = label_encoder.inverse_transform(y_pred)

# Evaluate
print("üìä Classification Report:")
print(classification_report(y_test_labels, y_pred_labels))
print("üßæ Confusion Matrix:")
print(confusion_matrix(y_test_labels, y_pred_labels))
accuracy = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy: {accuracy * 100:.2f}%")

"""**32 mfcc random forest,48.15%**"""

import os
import librosa
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Path to your folder with 'monkeys', 'squirrels', 'no_wilds'
base_path = '/content/drive/MyDrive/animal_sounds'

# üì• Feature extraction with MFCC + Chroma + Spectral Contrast
def extract_32_features(file_path, segment_duration=5.0):
    try:
        audio, sr = librosa.load(file_path, duration=segment_duration)

        # Feature extraction
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)

        # Combine all features by taking their mean across time axis
        mfcc_mean = np.mean(mfcc.T, axis=0)
        chroma_mean = np.mean(chroma.T, axis=0)
        contrast_mean = np.mean(contrast.T, axis=0)

        # Final 32-feature vector
        combined_features = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
        return combined_features

    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# üîÑ Load features and labels
features = []
labels = []
for label in os.listdir(base_path):
    class_dir = os.path.join(base_path, label)
    if os.path.isdir(class_dir):
        for file in os.listdir(class_dir):
            if file.endswith(".wav"):
                file_path = os.path.join(class_dir, file)
                feat = extract_32_features(file_path)
                if feat is not None:
                    features.append(feat)
                    labels.append(label)

# Convert to numpy arrays
X = np.array(features)
y = np.array(labels)

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)

# üå≥ Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# üéØ Predict
y_pred = rf_model.predict(X_test)

# Decode labels for reporting
y_test_labels = label_encoder.inverse_transform(y_test)
y_pred_labels = label_encoder.inverse_transform(y_pred)

# üßæ Evaluate
print("üìä Classification Report:")
print(classification_report(y_test_labels, y_pred_labels))
print("üßæ Confusion Matrix:")
print(confusion_matrix(y_test_labels, y_pred_labels))
accuracy = accuracy_score(y_test, y_pred)
print(f"\n‚úÖ Accuracy: {accuracy * 100:.2f}%")

"""**mfcc 32 random forest prediction**"""

from google.colab import files
import numpy as np
import librosa

# üì§ Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# ‚úÖ Use the same 32-feature extraction (MFCC + Chroma + Contrast) with best energy segment
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_energy = -np.inf
        best_features = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)

            segment = audio[start_sample:end_sample]
            if len(segment) < int(segment_duration * sr):
                continue

            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            chroma = librosa.feature.chroma_stft(y=segment, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr)

            mfcc_mean = np.mean(mfcc.T, axis=0)
            chroma_mean = np.mean(chroma.T, axis=0)
            contrast_mean = np.mean(contrast.T, axis=0)

            combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_energy:
                max_energy = energy
                best_features = combined

        return best_features
    except Exception as e:
        print(f"‚ùå Error processing {file_path}: {e}")
        return None

# üîç Prediction function
def predict_and_alert(file_path, model, label_encoder, scaler):
    feat = extract_best_features(file_path)
    if feat is None:
        print("‚ùå Could not extract features.")
        return

    feat = feat.reshape(1, -1)
    feat = scaler.transform(feat)  # ‚ö†Ô∏è Apply the same scaling as used in training

    probs = model.predict_proba(feat)[0]
    pred_idx = np.argmax(probs)
    pred_label = label_encoder.inverse_transform([pred_idx])[0]
    confidence = probs[pred_idx] * 100

    print(f"\nüîä Predicted: {pred_label}")
    print(f"üìà Confidence: {confidence:.2f}%")

    # ‚ö†Ô∏è Action logic
    if pred_label in ['monkeys', 'squirrels'] and confidence >= 50:
        print("üö® Wild animal detected! ‚ö†Ô∏è Action required.")
    else:
        print("‚úÖ No wild animal detected. No action required.")

# ‚úÖ Call the function (make sure rf_model, label_encoder, and scaler are loaded)
predict_and_alert(audio_path, rf_model, label_encoder, scaler)

"""**Random forest,some wilds correct,mfcc 13**"""

from google.colab import files
import numpy as np

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# Function to extract features (same as before)
def extract_features(file_path):
    try:
        audio, sr = librosa.load(file_path, duration=5)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        mfcc_scaled = np.mean(mfcc.T, axis=0)
        return mfcc_scaled
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

def predict_and_alert(file_path, model, label_encoder):
    feat = extract_features(file_path)
    if feat is None:
        print("‚ùå Could not extract features.")
        return

    feat = feat.reshape(1, -1)
    probs = model.predict_proba(feat)[0]
    pred_idx = np.argmax(probs)
    pred_label = label_encoder.inverse_transform([pred_idx])[0]
    confidence = probs[pred_idx] * 100

    print(f"\nüîä Predicted: {pred_label}")
    print(f"üìà Confidence: {confidence:.2f}%")

    # ‚úîÔ∏è Corrected logic
    if pred_label in ['monkeys', 'squirrels'] and confidence >= 50:
        print("‚ö†Ô∏è Wild animal detected! Action required.")
    else:
        print("‚úÖ No wild animal detected. No action required.")
predict_and_alert(audio_path, rf_model, label_encoder)

"""**Training using simple neural network**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Convert features to NumPy array
features = np.array(features)

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(labels)
y_categorical = to_categorical(y_encoded)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, y_categorical, test_size=0.2, random_state=42)

# Define model
model = Sequential([
    Dense(128, activation='relu', input_shape=(features.shape[1],)),
    Dense(64, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes: monkey, squirrel, no_wild
])

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train
model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_test, y_test))

# Evaluate
loss, acc = model.evaluate(X_test, y_test)
print(f"\nüìà Neural Network Accuracy: {acc * 100:.2f}%")

"""**Working code!!!!**"""

from google.colab import files
import librosa
import numpy as np

# Upload audio file
uploaded = files.upload()
file_path = next(iter(uploaded))  # Get the file name

# Function to extract features (same method as training)
def extract_features(file_path, max_len=5):
    audio, sr = librosa.load(file_path, duration=max_len)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    mfcc = np.mean(mfcc.T, axis=0)
    return mfcc

# Predict function
def predict_audio(file_path, model, label_encoder, threshold=0.50):
    feat = extract_features(file_path)
    feat = feat.reshape(1, -1)  # reshape for prediction
    probs = model.predict(feat)[0]
    pred_idx = np.argmax(probs)
    pred_label = label_encoder.inverse_transform([pred_idx])[0]
    confidence = probs[pred_idx]

    print(f"üîä Predicted: {pred_label}")
    print(f"üìà Confidence: {confidence * 100:.2f}%")

    if pred_label in ['monkeys', 'squirrels'] and confidence >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

# Run prediction
predict_audio(file_path, model, le)

"""**Wild animals?non wild**-working model: Final using NN"""

import numpy as np
import librosa
from google.colab import files

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# Function to extract MFCC features from audio
def extract_features(file_path, max_len=5):
    try:
        audio, sr = librosa.load(file_path, duration=max_len)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        mfcc = np.mean(mfcc.T, axis=0)
        return mfcc
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Predict function
def predict_audio(file_path, model, label_encoder, threshold=0.5):
    print("üìã Available classes:", list(label_encoder.classes_))  # For debugging

    feature = extract_features(file_path)
    if feature is None:
        print("‚ùå Could not extract features.")
        return

    feature = feature.reshape(1, -1)
    probs = model.predict(feature)[0]

    # Decode top prediction
    top_idx = np.argmax(probs)
    top_label = label_encoder.inverse_transform([top_idx])[0]
    top_conf = probs[top_idx]

    # Combine wild animal probabilities (safely)
    wild_labels = ['monkeys', 'squirrels']
    wild_conf = 0
    for label in wild_labels:
        if label in label_encoder.classes_:
            idx = np.where(label_encoder.classes_ == label)[0][0]
            wild_conf += probs[idx]

    print(f"\nüîä Top Prediction: {top_label} ({top_conf * 100:.2f}%)")
    print(f"üìä Wild Animal Confidence (Monkey + Squirrel): {wild_conf * 100:.2f}%")

    if wild_conf >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

# Run the prediction
predict_audio(audio_path, model, le, threshold=0.5)

"""**Train data with graph of accuracy,44%**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Convert features to NumPy array
features = np.array(features)

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(labels)
y_categorical = to_categorical(y_encoded)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, y_categorical, test_size=0.2, random_state=42)

# Define model
model = Sequential([
    Dense(128, activation='relu', input_shape=(features.shape[1],)),
    Dense(64, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes: monkey, squirrel, no_wild
])

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train
history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_test, y_test))

# Evaluate
loss, acc = model.evaluate(X_test, y_test)
print(f"\nüìà Neural Network Accuracy: {acc * 100:.2f}%")
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict on the test set
y_pred_probs = model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)

# Plot
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("üìä Confusion Matrix")
plt.grid(False)
plt.show()


# üéØ Plot accuracy and loss
plt.figure(figsize=(12, 5))

# Accuracy graph
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss graph
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""**With confidence graph,13 mfcc**"""

import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import files

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# Function to extract MFCC features from audio
def extract_features(file_path, max_len=5):
    try:
        audio, sr = librosa.load(file_path, duration=max_len)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        mfcc = np.mean(mfcc.T, axis=0)
        return mfcc
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None
from datetime import datetime
import pandas as pd

# Initialize log for pattern analysis
try:
    detection_log = pd.read_csv("detection_log.csv")
except:
    detection_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

# Predict function with confidence graph
def predict_audio(file_path, model, label_encoder, threshold=0.5):
    print("üìã Available classes:", list(label_encoder.classes_))

    feature = extract_features(file_path)
    if feature is None:
        print("‚ùå Could not extract features.")
        return

    feature = feature.reshape(1, -1)
    probs = model.predict(feature)[0]

    # Decode top prediction
    top_idx = np.argmax(probs)
    top_label = label_encoder.inverse_transform([top_idx])[0]
    top_conf = probs[top_idx]

    # Combine wild animal probabilities
    wild_labels = ['monkeys', 'squirrels']
    wild_conf = 0
    for label in wild_labels:
        if label in label_encoder.classes_:
            idx = np.where(label_encoder.classes_ == label)[0][0]
            wild_conf += probs[idx]

    print(f"\nüîä Top Prediction: {top_label} ({top_conf * 100:.2f}%)")
    print(f"üìä Wild Animal Confidence (Monkey + Squirrel): {wild_conf * 100:.2f}%")
    # Log the top prediction with timestamp
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    detection_log.loc[len(detection_log)] = [timestamp, top_label, top_conf]
    detection_log.to_csv("detection_log.csv", index=False)

    if wild_conf >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

    # üîΩ Plot class probabilities as a confidence bar chart
    class_labels = list(label_encoder.classes_)
    plt.figure(figsize=(8, 4))
    bars = plt.bar(class_labels, probs * 100, color=['orange' if lbl in wild_labels else 'green' for lbl in class_labels])
    plt.title('üéØ Confidence per Class')
    plt.ylabel('Confidence (%)')
    plt.ylim(0, 100)
    plt.grid(True, linestyle='--', alpha=0.6)

    # Annotate bars with confidence values
    for bar, prob in zip(bars, probs):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f"{prob * 100:.1f}%", ha='center', fontsize=9)

    plt.show()
    # ‚åõÔ∏è Pattern Analysis - Frequency of detections by hour
    detection_log["timestamp"] = pd.to_datetime(detection_log["timestamp"])
    detection_log["hour"] = detection_log["timestamp"].dt.hour

    # Filter for wild animal detections
    wild_detections = detection_log[detection_log["label"].isin(wild_labels)]

    # Count by hour
    hourly_counts = wild_detections.groupby("hour").size()

    # Plot
    plt.figure(figsize=(8, 4))
    hourly_counts.plot(kind='bar', color='tomato')
    plt.title("üìÖ Wild Animal Detections by Hour")
    plt.xlabel("Hour of Day")
    plt.ylabel("Detection Count")
    plt.xticks(rotation=0)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()


# Run the prediction
predict_audio(audio_path, model, le, threshold=0.5)

"""NN with 48% accuracy"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dropout

import matplotlib.pyplot as plt

# Convert features to NumPy array
features = np.array(features)

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(labels)
y_categorical = to_categorical(y_encoded)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(features, y_categorical, test_size=0.2, random_state=42)

# Define model
model = Sequential([
    Dense(256, activation='relu', input_shape=(features.shape[1],)),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(3, activation='softmax')
])

# Compile
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train
history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_test, y_test))

# Evaluate
loss, acc = model.evaluate(X_test, y_test)
print(f"\nüìà Neural Network Accuracy: {acc * 100:.2f}%")
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict on the test set
y_pred_probs = model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)

# Plot
plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("üìä Confusion Matrix")
plt.grid(False)
plt.show()


# üéØ Plot accuracy and loss
plt.figure(figsize=(12, 5))

# Accuracy graph
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss graph
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""**Training NN with 32 mfcc,76% accuracy**"""

import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dropout


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# -------------------------------
# üì• Feature Extraction (32-D)
# -------------------------------
def extract_best_features(file_path, segment_duration=5.0, hop_duration=1.0):
    try:
        audio, sr = librosa.load(file_path)
        total_duration = librosa.get_duration(y=audio, sr=sr)
        max_energy = -np.inf
        best_features = None

        for start in np.arange(0, total_duration - segment_duration + 1, hop_duration):
            end = start + segment_duration
            start_sample = int(start * sr)
            end_sample = int(end * sr)
            segment = audio[start_sample:end_sample]

            if len(segment) < int(segment_duration * sr):
                continue

            mfcc = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=13)
            chroma = librosa.feature.chroma_stft(y=segment, sr=sr)
            contrast = librosa.feature.spectral_contrast(y=segment, sr=sr)

            mfcc_mean = np.mean(mfcc.T, axis=0)
            chroma_mean = np.mean(chroma.T, axis=0)
            contrast_mean = np.mean(contrast.T, axis=0)

            combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
            energy = np.sum(mfcc_mean ** 2)

            if energy > max_energy:
                max_energy = energy
                best_features = combined

        return best_features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# ---------------------------------
# üìÅ Load Dataset from Folders
# ---------------------------------
def load_features_from_folders(base_path='/content/drive/MyDrive/animal_sounds'):
    features = []
    labels = []
    class_folders = ['monkeys', 'squirrels', 'no_wilds']

    for label in class_folders:
        folder_path = os.path.join(base_path, label)
        if not os.path.exists(folder_path):
            print(f"‚ùå Folder not found: {folder_path}")
            continue

        for file in os.listdir(folder_path):
            if file.endswith('.wav'):
                file_path = os.path.join(folder_path, file)
                feat = extract_best_features(file_path)
                if feat is not None:
                    features.append(feat)
                    labels.append(label)

    return np.array(features), np.array(labels)

# ------------------------------
# üöÄ Load and Prepare the Data
# ------------------------------
features, labels = load_features_from_folders()
print(f"‚úÖ Loaded {len(features)} samples with {features.shape[1]} features each.")

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(labels)
y_categorical = to_categorical(y_encoded)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    features, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical
)

# ----------------------------------
# üß† Define and Train Neural Network
# ----------------------------------
model = Sequential([
Dense(128, activation='relu', input_shape=(features.shape[1],)),
Dense(64, activation='relu'),
Dense(3, activation='softmax')  # 3 classes
])
#model = Sequential([
 #   Dense(128, activation='relu', input_shape=(features.shape[1],)),
  #  Dropout(0.3),
   # Dense(64, activation='relu'),
    #Dropout(0.2),
    #Dense(3, activation='softmax')
#])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_test, y_test))

# -------------------
# üéØ Evaluation
# -------------------
loss, acc = model.evaluate(X_test, y_test)
print(f"\nüìà Neural Network Accuracy: {acc * 100:.2f}%")

# Confusion Matrix
y_pred_probs = model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_true_classes, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
from tensorflow.keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, callbacks=[early_stop])

plt.figure(figsize=(6, 5))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("üìä Confusion Matrix")
plt.grid(False)
plt.show()

# -----------------------
# üìà Plot Training Curves
# -----------------------
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""**32 mfcc prediction**"""

import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import files
from tensorflow.keras.models import load_model
from datetime import datetime

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))
import pytz
# Set your local timezone (change to your region if needed)
local_tz = pytz.timezone("Asia/Kolkata")  # Example: IST
upload_time = datetime.now(pytz.utc).astimezone(local_tz)


# Function to extract MFCC features from audio
def extract_features(file_path, max_len=5):
    try:
        audio, sr = librosa.load(file_path, duration=max_len)

        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)

        mfcc_mean = np.mean(mfcc.T, axis=0)
        chroma_mean = np.mean(chroma.T, axis=0)
        contrast_mean = np.mean(contrast.T, axis=0)

        combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
        return combined  # ‚úÖ Total 32 features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

from datetime import datetime
import pandas as pd

# Initialize log for pattern analysis
try:
    detection_log = pd.read_csv("detection_log.csv")
except:
    detection_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

# Predict function with confidence graph
def predict_audio(file_path, model, label_encoder, threshold=0.5,upload_time=None):
    print("üìã Available classes:", list(label_encoder.classes_))

    feature = extract_features(file_path)
    if feature is None:
        print("‚ùå Could not extract features.")
        return

    feature = feature.reshape(1, -1)
    probs = model.predict(feature)[0]

    # Decode top prediction
    top_idx = np.argmax(probs)
    top_label = label_encoder.inverse_transform([top_idx])[0]
    top_conf = probs[top_idx]

    # Combine wild animal probabilities
    wild_labels = ['monkeys', 'squirrels']
    wild_conf = 0
    for label in wild_labels:
        if label in label_encoder.classes_:
            idx = np.where(label_encoder.classes_ == label)[0][0]
            wild_conf += probs[idx]

    print(f"\nüîä Top Prediction: {top_label} ({top_conf * 100:.2f}%)")
    print(f"üìä Wild Animal Confidence (Monkey + Squirrel): {wild_conf * 100:.2f}%")
    # Log the top prediction with timestamp
    timestamp = upload_time.strftime('%H:%M:%S') if upload_time else datetime.now().strftime('%H:%M:%S')
    detection_log.loc[len(detection_log)] = [timestamp, top_label, top_conf]
    detection_log.to_csv("detection_log.csv", index=False)

    if wild_conf >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

    # üîΩ Plot class probabilities as a confidence bar chart
    class_labels = list(label_encoder.classes_)
    plt.figure(figsize=(8, 4))
    bars = plt.bar(class_labels, probs * 100, color=['orange' if lbl in wild_labels else 'green' for lbl in class_labels])
    plt.title('üéØ Confidence per Class')
    plt.ylabel('Confidence (%)')
    plt.ylim(0, 100)
    plt.grid(True, linestyle='--', alpha=0.6)

    # Annotate bars with confidence values
    for bar, prob in zip(bars, probs):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f"{prob * 100:.1f}%", ha='center', fontsize=9)

    plt.show()
    # ‚åõÔ∏è Pattern Analysis - Peak time of day for each animal
    detection_log["timestamp"] = pd.to_datetime(detection_log["timestamp"])
    detection_log["date"] = detection_log["timestamp"].dt.date
    detection_log["hour_min"] = detection_log["timestamp"].dt.strftime('%H:%M')

    for animal in wild_labels:
        print(f"\nüìä Analyzing pattern for: {animal}")
        animal_data = detection_log[detection_log["label"] == animal]

        if animal_data.empty:
            print(f"‚ö†Ô∏è No data found for {animal}.")
            continue

        # Group by date and 30-min range to get daily peaks
        animal_data["time_range"] = animal_data["timestamp"].dt.floor("30min")
        daily_peak_times = (
            animal_data.groupby(["date", "time_range"])
            .size()
            .reset_index(name="count")
            .sort_values(["date", "count"], ascending=[True, False])
            .drop_duplicates(subset=["date"])
        )

        # Find the most frequent peak time across all days
        peak_counts = daily_peak_times["time_range"].value_counts()
        most_common_time = peak_counts.idxmax()
        peak_count = peak_counts.max()

        time_str = most_common_time.strftime("%I:%M %p")
        tomorrow_time_str = (most_common_time + pd.Timedelta(days=1)).strftime("%I:%M %p")

        print(f"üìà Most frequent {animal} visit time: {time_str} ({peak_count} days)")
        print(f"üîÆ {animal.capitalize()}s likely to visit around {tomorrow_time_str} tomorrow.")

        # Plot only the most common peak times
        plt.figure(figsize=(8, 4))
        peak_counts_sorted = peak_counts.sort_index()
        peak_counts_sorted.index = peak_counts_sorted.index.strftime("%I:%M %p")
        peak_counts.sort_index().plot(kind="bar", color="tomato")
        plt.title(f"üî• Peak {animal.capitalize()} Visit Times (Daily Peaks Only)")
        plt.xlabel("Time")
        plt.ylabel("Number of Days")
        plt.xticks(rotation=45)
        plt.grid(True, linestyle="--", alpha=0.6)
        plt.tight_layout()
        plt.show()


# Run the prediction
predict_audio(audio_path, model, le, threshold=0.5,upload_time=upload_time)

"""**with storing data on detection log file**"""

import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import files
from tensorflow.keras.models import load_model
from datetime import datetime
import pandas as pd
import pytz

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# Set your local timezone (change to your region if needed)
local_tz = pytz.timezone("Asia/Kolkata")  # Example: IST
upload_time = datetime.now(pytz.utc).astimezone(local_tz)

# Function to extract MFCC features from audio
def extract_features(file_path, max_len=5):
    try:
        audio, sr = librosa.load(file_path, duration=max_len)

        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)

        mfcc_mean = np.mean(mfcc.T, axis=0)
        chroma_mean = np.mean(chroma.T, axis=0)
        contrast_mean = np.mean(contrast.T, axis=0)

        combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
        return combined  # ‚úÖ Total 32 features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Initialize log for pattern analysis
try:
    detection_log = pd.read_csv("detection_log.csv")
except:
    detection_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

# Predict function with confidence graph
def predict_audio(file_path, model, label_encoder, threshold=0.5, upload_time=None):
    print("üìã Available classes:", list(label_encoder.classes_))

    feature = extract_features(file_path)
    if feature is None:
        print("‚ùå Could not extract features.")
        return

    feature = feature.reshape(1, -1)
    probs = model.predict(feature)[0]

    # Decode top prediction
    top_idx = np.argmax(probs)
    top_label = label_encoder.inverse_transform([top_idx])[0]
    top_conf = probs[top_idx]

    # Combine wild animal probabilities
    wild_labels = ['monkeys', 'squirrels']
    wild_conf = 0
    for label in wild_labels:
        if label in label_encoder.classes_:
            idx = np.where(label_encoder.classes_ == label)[0][0]
            wild_conf += probs[idx]

    print(f"\nüîä Top Prediction: {top_label} ({top_conf * 100:.2f}%)")
    print(f"üìä Wild Animal Confidence (Monkey + Squirrel): {wild_conf * 100:.2f}%")

    # Log the top prediction with timestamp
    timestamp = upload_time.strftime('%Y-%m-%d %H:%M:%S') if upload_time else datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    detection_log.loc[len(detection_log)] = [timestamp, top_label, top_conf]
    detection_log.to_csv("detection_log.csv", index=False)

    if wild_conf >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

    # üîΩ Plot class probabilities as a confidence bar chart
    class_labels = list(label_encoder.classes_)
    plt.figure(figsize=(8, 4))
    bars = plt.bar(class_labels, probs * 100, color=['orange' if lbl in wild_labels else 'green' for lbl in class_labels])
    plt.title('üéØ Confidence per Class')
    plt.ylabel('Confidence (%)')
    plt.ylim(0, 100)
    plt.grid(True, linestyle='--', alpha=0.6)

    # Annotate bars with confidence values
    for bar, prob in zip(bars, probs):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f"{prob * 100:.1f}%", ha='center', fontsize=9)

    plt.show()

    # ‚åõÔ∏è Pattern Analysis - Peak time of day for each animal
    detection_log["timestamp"] = pd.to_datetime(detection_log["timestamp"])
    detection_log["date"] = detection_log["timestamp"].dt.date
    detection_log["hour_min"] = detection_log["timestamp"].dt.strftime('%H:%M')

    # Analyze the pattern of detections per day
    detections_per_day = detection_log.groupby('date').size()

    # Plot number of detections per day
    plt.figure(figsize=(8, 4))
    detections_per_day.plot(kind="bar", color="tomato")
    plt.title("üî• Number of Detections per Day")
    plt.xlabel("Date")
    plt.ylabel("Number of Detections")
    plt.xticks(rotation=45)
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.tight_layout()
    plt.show()

# Run the prediction
predict_audio(audio_path, model, le, threshold=0.5, upload_time=upload_time)

"""**Pettern analysis to alert**"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the detection log
try:
    detection_log = pd.read_csv("detection_log.csv")
    detection_log["timestamp"] = pd.to_datetime(detection_log["timestamp"])
except Exception as e:
    print(f"Error loading detection log: {e}")
    detection_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

if detection_log.empty:
    print("‚ö†Ô∏è No detection data available.")
else:
    # Define wild animals to track
    wild_labels = ['monkeys', 'squirrels']
    detection_log["time_range"] = detection_log["timestamp"].dt.floor("30min")

    for animal in wild_labels:
        animal_data = detection_log[detection_log["label"] == animal]

        if animal_data.empty:
            print(f"üì≠ No detections found for {animal}.")
            continue

        # Count how often each 30-min window has detections
        peak_times = animal_data["time_range"].value_counts().sort_index()
        peak_times.index = peak_times.index.strftime("%I:%M %p")

        # Find peak detection time
        peak_time = peak_times.idxmax()
        peak_count = peak_times.max()


        print(f"\nüì¢ ALERT: {animal.capitalize()}s are most frequently detected at {formatted_peak_time}")
        print(f"üïí Detected {peak_count} times during this time slot. Farmer should stay alert.")

        # Plot
        plt.figure(figsize=(8, 4))
        peak_times.plot(kind='bar', color='orange' if animal == 'monkeys' else 'green')
        plt.title(f"üîç Peak Visit Times for {animal.capitalize()}")
        plt.xlabel("Time Slot")
        plt.ylabel("Detections")
        plt.xticks(rotation=45)
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.tight_layout()
        plt.show()

"""**CNN feature extraction,40% accuracy oll**"""

import librosa
import numpy as np

def extract_mfcc_2d(file_path, n_mfcc=40, max_len=44):  # ~1 second = 44 frames
    try:
        audio, sr = librosa.load(file_path, duration=2.0)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)

        # Pad or truncate to fixed length
        if mfcc.shape[1] < max_len:
            pad_width = max_len - mfcc.shape[1]
            mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')
        else:
            mfcc = mfcc[:, :max_len]

        return mfcc  # shape: (n_mfcc, time)
    except Exception as e:
        print(f"Error extracting MFCC from {file_path}: {e}")
        return None

import os
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

data = []
labels = []

base_dir = '/content/drive/MyDrive/animal_sounds'  # adjust path if needed
for label in os.listdir(base_dir):
    folder = os.path.join(base_dir, label)
    for file in os.listdir(folder):
        if file.endswith(".wav"):
            path = os.path.join(folder, file)
            mfcc = extract_mfcc_2d(path)
            if mfcc is not None:
                data.append(mfcc)
                labels.append(label)

X = np.array(data)
X = X[..., np.newaxis]  # CNN expects 4D: (samples, height, width, channels)

# Encode labels
le = LabelEncoder()
y = le.fit_transform(labels)
from tensorflow.keras.utils import to_categorical
y_cat = to_categorical(y)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]),
    MaxPooling2D((2, 2)),
    Dropout(0.3),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.3),

    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y_train.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

history = model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_test, y_test))

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()
loss, acc = model.evaluate(X_test, y_test)
print(f"\nüìà Neural Network Accuracy: {acc * 100:.2f}%")

import os
import librosa
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# 1. Extract MFCC (2D for CNN)
def extract_mfcc_2d(file_path, n_mfcc=40, max_len=100):
    try:
        audio, sr = librosa.load(file_path, duration=3.0)
        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)

        if mfcc.shape[1] < max_len:
            pad_width = max_len - mfcc.shape[1]
            mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')
        else:
            mfcc = mfcc[:, :max_len]

        return mfcc
    except Exception as e:
        print(f"Error: {e}")
        return None

# 2. Load Data
data = []
labels = []
base_dir = "/content/drive/MyDrive/animal_sounds"

for label in os.listdir(base_dir):
    class_dir = os.path.join(base_dir, label)
    for file in os.listdir(class_dir):
        if file.endswith(".wav"):
            path = os.path.join(class_dir, file)
            features = extract_mfcc_2d(path)
            if features is not None:
                data.append(features)
                labels.append(label)

# 3. Prepare data
X = np.array(data)
X = X[..., np.newaxis]  # Shape: (samples, 40, max_len, 1)

le = LabelEncoder()
y = le.fit_transform(labels)
y = to_categorical(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Build CNN Model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=X.shape[1:]),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.25),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.3),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(y.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 5. Train the model
history = model.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_test, y_test))

# 6. Evaluate
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"\n‚úÖ Test Accuracy: {test_acc*100:.2f}%")

# 7. Plot accuracy/loss
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Val')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.grid()
plt.show()

import numpy as np
import librosa
import matplotlib.pyplot as plt
from google.colab import files
from tensorflow.keras.models import load_model
from datetime import datetime
import pandas as pd
import pytz

# Upload the audio file
uploaded = files.upload()
audio_path = next(iter(uploaded))

# Set your local timezone (change to your region if needed)
local_tz = pytz.timezone("Asia/Kolkata")  # Example: IST
upload_time = datetime.now(pytz.utc).astimezone(local_tz)

# Function to extract MFCC features from audio
def extract_features(file_path, max_len=5):
    try:
        audio, sr = librosa.load(file_path, duration=max_len)

        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)

        mfcc_mean = np.mean(mfcc.T, axis=0)
        chroma_mean = np.mean(chroma.T, axis=0)
        contrast_mean = np.mean(contrast.T, axis=0)

        combined = np.hstack([mfcc_mean, chroma_mean, contrast_mean])
        return combined  # ‚úÖ Total 32 features
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None

# Initialize log for pattern analysis
try:
    detection_log = pd.read_csv("detection_log.csv")
except:
    detection_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

# Predict function with confidence graph
def predict_audio(file_path, model, label_encoder, threshold=0.5, upload_time=None):
    print("üìã Available classes:", list(label_encoder.classes_))

    feature = extract_features(file_path)
    if feature is None:
        print("‚ùå Could not extract features.")
        return

    feature = feature.reshape(1, -1)
    probs = model.predict(feature)[0]

    # Decode top prediction
    top_idx = np.argmax(probs)
    top_label = label_encoder.inverse_transform([top_idx])[0]
    top_conf = probs[top_idx]

    # Combine wild animal probabilities
    wild_labels = ['monkeys', 'squirrels']
    wild_conf = 0
    for label in wild_labels:
        if label in label_encoder.classes_:
            idx = np.where(label_encoder.classes_ == label)[0][0]
            wild_conf += probs[idx]

    print(f"\nüîä Top Prediction: {top_label} ({top_conf * 100:.2f}%)")
    print(f"üìä Wild Animal Confidence (Monkey + Squirrel): {wild_conf * 100:.2f}%")

    # Log the top prediction with timestamp
    timestamp = upload_time.strftime('%Y-%m-%d %H:%M:%S') if upload_time else datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    detection_log.loc[len(detection_log)] = [timestamp, top_label, top_conf]
    detection_log.to_csv("detection_log.csv", index=False)

    if wild_conf >= threshold:
        print("‚ö†Ô∏è Wild animal presence detected. Action required!")
    else:
        print("‚úÖ No wild animal detected. No action required.")

    # üîΩ Plot class probabilities as a confidence bar chart
    class_labels = list(label_encoder.classes_)
    plt.figure(figsize=(8, 4))
    bars = plt.bar(class_labels, probs * 100, color=['orange' if lbl in wild_labels else 'green' for lbl in class_labels])
    plt.title('üéØ Confidence per Class')
    plt.ylabel('Confidence (%)')
    plt.ylim(0, 100)
    plt.grid(True, linestyle='--', alpha=0.6)

    for bar, prob in zip(bars, probs):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f"{prob * 100:.1f}%", ha='center', fontsize=9)

    plt.show()

    # ‚åõÔ∏è Pattern Analysis - Peak time of day for each animal
    detection_log["timestamp"] = pd.to_datetime(detection_log["timestamp"])
    detection_log["date"] = detection_log["timestamp"].dt.date
    detection_log["hour_min"] = detection_log["timestamp"].dt.strftime('%H:%M')

    for animal in wild_labels:
        print(f"\nüìä Analyzing pattern for: {animal}")
        animal_data = detection_log[detection_log["label"] == animal]

        if animal_data.empty:
            print(f"‚ö†Ô∏è No data found for {animal}.")
            continue

        # Group by date and 30-min range to get daily peaks
        animal_data["time_range"] = animal_data["timestamp"].dt.floor("30min")
        daily_peak_times = (
            animal_data.groupby(["date", "time_range"])
            .size()
            .reset_index(name="count")
            .sort_values(["date", "count"], ascending=[True, False])
            .drop_duplicates(subset=["date"])
        )

        # Find the most frequent peak time across all days
        peak_counts = daily_peak_times["time_range"].value_counts()
        most_common_time = peak_counts.idxmax()
        peak_count = peak_counts.max()

        time_str = most_common_time.strftime("%I:%M %p")
        tomorrow_time_str = (most_common_time + pd.Timedelta(days=1)).strftime("%I:%M %p")

        print(f"üìà Most frequent {animal} visit time: {time_str} ({peak_count} days)")
        print(f"üîÆ {animal.capitalize()}s likely to visit around {tomorrow_time_str} tomorrow.")

        # Plot only the most common peak times
        plt.figure(figsize=(8, 4))
        peak_counts.sort_index().plot(kind="bar", color="tomato")
        plt.title(f"üî• Peak {animal.capitalize()} Visit Times (Daily Peaks Only)")
        plt.xlabel("Time")
        plt.ylabel("Number of Days")
        plt.xticks(rotation=45)
        plt.grid(True, linestyle="--", alpha=0.6)
        plt.tight_layout()
        plt.show()

# Run the prediction
predict_audio(audio_path, model, le, threshold=0.5, upload_time=upload_time)